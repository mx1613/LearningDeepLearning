{"cells":[{"cell_type":"markdown","source":"# Train a NN on the MNIST dataset","metadata":{"tags":[],"cell_id":"a6a9d78f210242c3977ab678c24f4a2e","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h1"}},{"cell_type":"markdown","source":"The MNIST dataset is a collection of hand-written digits, labelled with their corresponding true digit representation. We want to train a MLP (very simple feedforward or sequential network), to recognize hand-written digits. \n![Picture title](https://upload.wikimedia.org/wikipedia/commons/thumb/2/27/MnistExamples.png/320px-MnistExamples.png)\n","metadata":{"tags":[],"cell_id":"6bd8e7c1c9de41218f7a8b19e60db94a","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"## Import libraries and define symbolic constants","metadata":{"tags":[],"cell_id":"e580af3ed96d4f059da7d093048e931b","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"markdown","source":"### Install wandb to keep track of model performance","metadata":{"tags":[],"cell_id":"8f26b1b3de9a49068669180dd5dc84a7","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h3"}},{"cell_type":"code","source":"!pip install --upgrade wandb\n!wandb login ff97f4ffa6b4b35ec56fc229fc572b0ba72ac1fb","metadata":{"tags":[],"cell_id":"314b38056ca2491da13f301a52728ea7","source_hash":"10f68b6d","execution_start":1667680349204,"execution_millis":9181,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /root/venv/lib/python3.9/site-packages (0.13.5)\nRequirement already satisfied: six>=1.13.0 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from wandb) (1.16.0)\nRequirement already satisfied: setproctitle in /root/venv/lib/python3.9/site-packages (from wandb) (1.3.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from wandb) (2.28.1)\nRequirement already satisfied: PyYAML in /root/venv/lib/python3.9/site-packages (from wandb) (6.0)\nRequirement already satisfied: pathtools in /root/venv/lib/python3.9/site-packages (from wandb) (0.1.2)\nRequirement already satisfied: promise<3,>=2.0 in /root/venv/lib/python3.9/site-packages (from wandb) (2.3)\nRequirement already satisfied: GitPython>=1.0.0 in /root/venv/lib/python3.9/site-packages (from wandb) (3.1.29)\nRequirement already satisfied: Click!=8.0.0,>=7.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from wandb) (8.1.3)\nRequirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from wandb) (3.19.6)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /root/venv/lib/python3.9/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: psutil>=5.0.0 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: shortuuid>=0.5.0 in /root/venv/lib/python3.9/site-packages (from wandb) (1.0.9)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /root/venv/lib/python3.9/site-packages (from wandb) (1.10.1)\nRequirement already satisfied: setuptools in /root/venv/lib/python3.9/site-packages (from wandb) (58.1.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /root/venv/lib/python3.9/site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (1.26.12)\nRequirement already satisfied: certifi>=2017.4.17 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2022.9.24)\nRequirement already satisfied: charset-normalizer<3,>=2 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\nRequirement already satisfied: smmap<6,>=3.0.1 in /root/venv/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\nYou should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n\u001b[0m\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"### Import and initialize parameters","metadata":{"tags":[],"cell_id":"632ce21056c649a3a59a340a064cef06","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h3"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nimport wandb\nfrom wandb.keras import WandbCallback\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Flatten\n\nINPUT_SHAPE = (28, 28)\nACTIVATION_FUNCTION = 'sigmoid'\nN_CLASSES = 10\nOPTIMIZER = 'adam'\nMETRICS = ['accuracy']\nEPOCHS = 50\nVERBOSE = 1\nVALIDATION_SPLIT = 0.2\nWANDB_PROJECT = 'logistic-classification'\n\nwandb.init(project=WANDB_PROJECT)\nwandb.config = {\n'input_shape': INPUT_SHAPE,\n'activation_function': ACTIVATION_FUNCTION,\n'number_of_classes': N_CLASSES,\n'otpimizer': OPTIMIZER,\n'metrics': METRICS,\n'epochs': EPOCHS,\n'validation_split': VALIDATION_SPLIT\n}","metadata":{"tags":[],"cell_id":"666537f2439a41a39b83c068e7ac9fcf","source_hash":"c43a385d","execution_start":1667680358394,"execution_millis":12593,"is_output_hidden":false,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stderr","text":"2022-11-05 20:32:39.268811: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-11-05 20:32:39.498951: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2022-11-05 20:32:39.498983: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n2022-11-05 20:32:39.542697: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2022-11-05 20:32:42.155320: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n2022-11-05 20:32:42.155431: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n2022-11-05 20:32:42.155442: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\nFailed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpicklerick\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.13.5"},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/work/wandb/run-20221105_203250-11kmlk7n</code>"},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href=\"https://wandb.ai/picklerick/logistic-classification/runs/11kmlk7n\" target=\"_blank\">unique-tree-6</a></strong> to <a href=\"https://wandb.ai/picklerick/logistic-classification\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"},"metadata":{},"output_type":"display_data"}],"execution_count":2},{"cell_type":"markdown","source":"## Load MNIST dataset from Keras\r","metadata":{"tags":[],"cell_id":"6e91e6ab74d7437499ceb07ab15f2f6e","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"code","source":"mnist = keras.datasets.mnist\n(X_train, Y_train), (X_test, Y_test) = mnist.load_data()","metadata":{"tags":[],"cell_id":"e2d9d9f3c1174b1b8b296876601e1c85","source_hash":"24f9ab52","execution_start":1667680370886,"execution_millis":398,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## Normalize pixel values to be 0-1","metadata":{"tags":[],"cell_id":"c4dca8edae3c43438e557901f0265554","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"code","source":"X_train = X_train.astype(\"float32\")/255\nX_test = X_test.astype(\"float32\")/255\nY_train = Y_train.astype('int32')\nY_test = Y_test.astype('int32')\n","metadata":{"tags":[],"cell_id":"8ca6e8193064403784aafe392a3c2f70","source_hash":"19c79cc4","execution_start":1667680371285,"execution_millis":107,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Build the model","metadata":{"tags":[],"cell_id":"41631f2c8576462c83a69b110be6bc7c","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"markdown","source":"- We use the sequential class to create a linear stack of feedforward layers. In this we have:","metadata":{"tags":[],"cell_id":"d382a482b59d4640a314c70a487bad11","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-bullet"}},{"cell_type":"markdown","source":"- A layer that flattens the images, creating a 1D array from the 2D matrix","metadata":{"tags":[],"cell_id":"658255b9-f544-433d-8c57-f919464b9972","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-bullet"}},{"cell_type":"markdown","source":"- A layer that takes this array and passes it through a sigmoid function with 10 outputs (multiclass logistic regression)","metadata":{"tags":[],"cell_id":"cceaca4028984a35b7c2554c434d968c","is_collapsed":false,"formattedRanges":[{"url":"https://deepai.org/machine-learning-glossary-and-terms/softmax-layer","type":"link","ranges":[],"toCodePoint":119,"fromCodePoint":119}],"deepnote_cell_type":"text-cell-bullet"}},{"cell_type":"code","source":"model = keras.Sequential(\n    [\n        Flatten(input_shape=INPUT_SHAPE),\n        Dense(\n            N_CLASSES,\n            activation=ACTIVATION_FUNCTION\n            )\n    ]\n)\n\nmodel.summary()","metadata":{"tags":[],"cell_id":"c4cd2c9ba83b4338b23b221904ce3324","source_hash":"9bb2df09","execution_start":1667680371392,"execution_millis":121,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n flatten (Flatten)           (None, 784)               0         \n                                                                 \n dense (Dense)               (None, 10)                7850      \n                                                                 \n=================================================================\nTotal params: 7,850\nTrainable params: 7,850\nNon-trainable params: 0\n_________________________________________________________________\n2022-11-05 20:32:51.368833: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n2022-11-05 20:32:51.368871: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n2022-11-05 20:32:51.368893: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (p-ba4822a4-198a-4cdb-8280-0ca8d044b999): /proc/driver/nvidia/version does not exist\n2022-11-05 20:32:51.369179: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## Compile the model","metadata":{"tags":[],"cell_id":"4ecfb72e6d7d4cf4b6d5a4b5c67d1f62","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"markdown","source":"- We use the adam optimizer","metadata":{"tags":[],"cell_id":"b1eb7b48cb834ef08d236ba67b0a84f4","is_collapsed":false,"formattedRanges":[{"type":"marks","marks":{"code":true},"toCodePoint":16,"fromCodePoint":11}],"deepnote_cell_type":"text-cell-bullet"}},{"cell_type":"markdown","source":"- The loss function is sparse categorical cross-entropy, this is particularly well-suited for multi-class problems with a one-hot encoding ","metadata":{"tags":[],"cell_id":"ad15374eef244056bd61b7b33bbd21d1","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-bullet"}},{"cell_type":"markdown","source":"- We use accuracy to evaluate the performance of the model","metadata":{"tags":[],"cell_id":"06140865a42b43ba996a65a562084b47","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-bullet"}},{"cell_type":"code","source":"model.compile(\n    optimizer=OPTIMIZER,\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=METRICS\n)","metadata":{"tags":[],"cell_id":"359b0a5516894380a04d155f635fd77d","source_hash":"b7c7bb75","execution_start":1667680371512,"execution_millis":0,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Train the model","metadata":{"tags":[],"cell_id":"ea4c4a047ad344599b94b7dda7662a30","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"markdown","source":"We are now ready to train the model. We need to define the number of epochs and the batch size. ","metadata":{"tags":[],"cell_id":"89e5e4b6e765477d8d90a1e36c1b2dd5","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"- Epochs are the number of times the model is exposed to the training dataset. Each time, it will run the optimizer and try to minimize the loss function. ","metadata":{"tags":[],"cell_id":"96290fcbf4804bd59b897d7db344bfad","is_collapsed":false,"formattedRanges":[{"type":"marks","marks":{"code":true},"toCodePoint":7,"fromCodePoint":0}],"deepnote_cell_type":"text-cell-bullet"}},{"cell_type":"markdown","source":"- We split the training data in an 80% training and 20% validation per epoch. The validation set is used to compute the metric and tune hyperparameters, to avoid overfitting.","metadata":{"tags":[],"cell_id":"3e6ad52c25dc482f9f8098bf0d49f51f","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-bullet"}},{"cell_type":"code","source":"history = model.fit(\n    x=X_train, \n    y=Y_train, \n    epochs=EPOCHS,\n    validation_split=VALIDATION_SPLIT,\n    callbacks=[\n        WandbCallback(),\n        ],\n    )","metadata":{"tags":[],"cell_id":"feeecbe33e174a2cb317c82b3d33ea6e","source_hash":"1f242926","execution_start":1667680371512,"execution_millis":262908,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\nEpoch 1/50\n/shared-libs/python3.9/py/lib/python3.9/site-packages/keras/backend.py:5582: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n  output, from_logits = _get_logits(\n1495/1500 [============================>.] - ETA: 0s - loss: 0.5173 - accuracy: 0.8651INFO:tensorflow:Assets written to: /work/wandb/run-20221105_203250-11kmlk7n/files/model-best/assets\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_203250-11kmlk7n/files/model-best)... Done. 0.0s\n1500/1500 [==============================] - 7s 4ms/step - loss: 0.5168 - accuracy: 0.8651 - val_loss: 0.3198 - val_accuracy: 0.9122\nEpoch 2/50\n1500/1500 [==============================] - ETA: 0s - loss: 0.3187 - accuracy: 0.9117INFO:tensorflow:Assets written to: /work/wandb/run-20221105_203250-11kmlk7n/files/model-best/assets\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_203250-11kmlk7n/files/model-best)... Done. 0.0s\n1500/1500 [==============================] - 6s 4ms/step - loss: 0.3187 - accuracy: 0.9117 - val_loss: 0.2883 - val_accuracy: 0.9212\nEpoch 3/50\n1489/1500 [============================>.] - ETA: 0s - loss: 0.2930 - accuracy: 0.9181INFO:tensorflow:Assets written to: /work/wandb/run-20221105_203250-11kmlk7n/files/model-best/assets\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_203250-11kmlk7n/files/model-best)... Done. 0.0s\n1500/1500 [==============================] - 6s 4ms/step - loss: 0.2935 - accuracy: 0.9181 - val_loss: 0.2772 - val_accuracy: 0.9213\nEpoch 4/50\n1499/1500 [============================>.] - ETA: 0s - loss: 0.2816 - accuracy: 0.9212INFO:tensorflow:Assets written to: /work/wandb/run-20221105_203250-11kmlk7n/files/model-best/assets\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_203250-11kmlk7n/files/model-best)... Done. 0.0s\n1500/1500 [==============================] - 6s 4ms/step - loss: 0.2817 - accuracy: 0.9211 - val_loss: 0.2732 - val_accuracy: 0.9225\nEpoch 5/50\n1481/1500 [============================>.] - ETA: 0s - loss: 0.2738 - accuracy: 0.9228INFO:tensorflow:Assets written to: /work/wandb/run-20221105_203250-11kmlk7n/files/model-best/assets\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_203250-11kmlk7n/files/model-best)... Done. 0.0s\n1500/1500 [==============================] - 6s 4ms/step - loss: 0.2739 - accuracy: 0.9230 - val_loss: 0.2671 - val_accuracy: 0.9258\nEpoch 6/50\n1487/1500 [============================>.] - ETA: 0s - loss: 0.2686 - accuracy: 0.9250INFO:tensorflow:Assets written to: /work/wandb/run-20221105_203250-11kmlk7n/files/model-best/assets\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_203250-11kmlk7n/files/model-best)... Done. 0.0s\n1500/1500 [==============================] - 6s 4ms/step - loss: 0.2680 - accuracy: 0.9251 - val_loss: 0.2658 - val_accuracy: 0.9268\nEpoch 7/50\n1487/1500 [============================>.] - ETA: 0s - loss: 0.2638 - accuracy: 0.9256INFO:tensorflow:Assets written to: /work/wandb/run-20221105_203250-11kmlk7n/files/model-best/assets\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_203250-11kmlk7n/files/model-best)... Done. 0.0s\n1500/1500 [==============================] - 6s 4ms/step - loss: 0.2638 - accuracy: 0.9255 - val_loss: 0.2627 - val_accuracy: 0.9282\nEpoch 8/50\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.2607 - accuracy: 0.9271 - val_loss: 0.2694 - val_accuracy: 0.9249\nEpoch 9/50\n1498/1500 [============================>.] - ETA: 0s - loss: 0.2576 - accuracy: 0.9282INFO:tensorflow:Assets written to: /work/wandb/run-20221105_203250-11kmlk7n/files/model-best/assets\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_203250-11kmlk7n/files/model-best)... Done. 0.0s\n1500/1500 [==============================] - 5s 4ms/step - loss: 0.2575 - accuracy: 0.9283 - val_loss: 0.2605 - val_accuracy: 0.9289\nEpoch 10/50\n1500/1500 [==============================] - 6s 4ms/step - loss: 0.2555 - accuracy: 0.9289 - val_loss: 0.2610 - val_accuracy: 0.9299\nEpoch 11/50\n1500/1500 [==============================] - 5s 4ms/step - loss: 0.2532 - accuracy: 0.9294 - val_loss: 0.2613 - val_accuracy: 0.9301\nEpoch 12/50\n1497/1500 [============================>.] - ETA: 0s - loss: 0.2510 - accuracy: 0.9300INFO:tensorflow:Assets written to: /work/wandb/run-20221105_203250-11kmlk7n/files/model-best/assets\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_203250-11kmlk7n/files/model-best)... Done. 0.0s\n1500/1500 [==============================] - 6s 4ms/step - loss: 0.2508 - accuracy: 0.9301 - val_loss: 0.2604 - val_accuracy: 0.9306\nEpoch 13/50\n1497/1500 [============================>.] - ETA: 0s - loss: 0.2495 - accuracy: 0.9306INFO:tensorflow:Assets written to: /work/wandb/run-20221105_203250-11kmlk7n/files/model-best/assets\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_203250-11kmlk7n/files/model-best)... Done. 0.0s\n1500/1500 [==============================] - 6s 4ms/step - loss: 0.2496 - accuracy: 0.9305 - val_loss: 0.2593 - val_accuracy: 0.9307\nEpoch 14/50\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.2482 - accuracy: 0.9307 - val_loss: 0.2621 - val_accuracy: 0.9308\nEpoch 15/50\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.2464 - accuracy: 0.9309 - val_loss: 0.2628 - val_accuracy: 0.9290\nEpoch 16/50\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.2452 - accuracy: 0.9317 - val_loss: 0.2651 - val_accuracy: 0.9285\nEpoch 17/50\n1500/1500 [==============================] - 5s 4ms/step - loss: 0.2442 - accuracy: 0.9320 - val_loss: 0.2601 - val_accuracy: 0.9303\nEpoch 18/50\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.2433 - accuracy: 0.9321 - val_loss: 0.2646 - val_accuracy: 0.9293\nEpoch 19/50\n1500/1500 [==============================] - 5s 4ms/step - loss: 0.2427 - accuracy: 0.9324 - val_loss: 0.2625 - val_accuracy: 0.9302\nEpoch 20/50\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.2414 - accuracy: 0.9332 - val_loss: 0.2639 - val_accuracy: 0.9293\nEpoch 21/50\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.2406 - accuracy: 0.9322 - val_loss: 0.2640 - val_accuracy: 0.9289\nEpoch 22/50\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.2394 - accuracy: 0.9326 - val_loss: 0.2641 - val_accuracy: 0.9308\nEpoch 23/50\n1500/1500 [==============================] - 5s 4ms/step - loss: 0.2388 - accuracy: 0.9330 - val_loss: 0.2617 - val_accuracy: 0.9308\nEpoch 24/50\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.2383 - accuracy: 0.9334 - val_loss: 0.2653 - val_accuracy: 0.9297\nEpoch 25/50\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.2377 - accuracy: 0.9338 - val_loss: 0.2629 - val_accuracy: 0.9313\nEpoch 26/50\n1500/1500 [==============================] - 5s 4ms/step - loss: 0.2368 - accuracy: 0.9342 - val_loss: 0.2634 - val_accuracy: 0.9308\nEpoch 27/50\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.2365 - accuracy: 0.9343 - val_loss: 0.2626 - val_accuracy: 0.9302\nEpoch 28/50\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.2354 - accuracy: 0.9346 - val_loss: 0.2681 - val_accuracy: 0.9277\nEpoch 29/50\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.2349 - accuracy: 0.9351 - val_loss: 0.2668 - val_accuracy: 0.9295\nEpoch 30/50\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.2348 - accuracy: 0.9343 - val_loss: 0.2667 - val_accuracy: 0.9300\nEpoch 31/50\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.2339 - accuracy: 0.9348 - val_loss: 0.2659 - val_accuracy: 0.9310\nEpoch 32/50\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.2339 - accuracy: 0.9354 - val_loss: 0.2678 - val_accuracy: 0.9312\nEpoch 33/50\n1500/1500 [==============================] - 5s 4ms/step - loss: 0.2332 - accuracy: 0.9356 - val_loss: 0.2684 - val_accuracy: 0.9292\nEpoch 34/50\n1500/1500 [==============================] - 5s 4ms/step - loss: 0.2328 - accuracy: 0.9351 - val_loss: 0.2675 - val_accuracy: 0.9302\nEpoch 35/50\n1500/1500 [==============================] - 5s 4ms/step - loss: 0.2320 - accuracy: 0.9359 - val_loss: 0.2655 - val_accuracy: 0.9312\nEpoch 36/50\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.2316 - accuracy: 0.9356 - val_loss: 0.2696 - val_accuracy: 0.9299\nEpoch 37/50\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.2315 - accuracy: 0.9351 - val_loss: 0.2682 - val_accuracy: 0.9303\nEpoch 38/50\n1500/1500 [==============================] - 5s 4ms/step - loss: 0.2309 - accuracy: 0.9351 - val_loss: 0.2700 - val_accuracy: 0.9298\nEpoch 39/50\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.2305 - accuracy: 0.9356 - val_loss: 0.2673 - val_accuracy: 0.9302\nEpoch 40/50\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.2301 - accuracy: 0.9363 - val_loss: 0.2689 - val_accuracy: 0.9299\nEpoch 41/50\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.2299 - accuracy: 0.9360 - val_loss: 0.2690 - val_accuracy: 0.9302\nEpoch 42/50\n1500/1500 [==============================] - 5s 4ms/step - loss: 0.2294 - accuracy: 0.9360 - val_loss: 0.2714 - val_accuracy: 0.9289\nEpoch 43/50\n1500/1500 [==============================] - 5s 4ms/step - loss: 0.2291 - accuracy: 0.9366 - val_loss: 0.2731 - val_accuracy: 0.9283\nEpoch 44/50\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.2292 - accuracy: 0.9358 - val_loss: 0.2725 - val_accuracy: 0.9293\nEpoch 45/50\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.2284 - accuracy: 0.9362 - val_loss: 0.2715 - val_accuracy: 0.9287\nEpoch 46/50\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.2284 - accuracy: 0.9364 - val_loss: 0.2727 - val_accuracy: 0.9289\nEpoch 47/50\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.2281 - accuracy: 0.9359 - val_loss: 0.2729 - val_accuracy: 0.9266\nEpoch 48/50\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.2278 - accuracy: 0.9363 - val_loss: 0.2750 - val_accuracy: 0.9270\nEpoch 49/50\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.2276 - accuracy: 0.9358 - val_loss: 0.2728 - val_accuracy: 0.9308\nEpoch 50/50\n1500/1500 [==============================] - 5s 4ms/step - loss: 0.2276 - accuracy: 0.9364 - val_loss: 0.2719 - val_accuracy: 0.9302\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## Test the model on unseen data","metadata":{"tags":[],"cell_id":"515f110f18684bab828277dff4dcfbd8","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"code","source":"test_loss, test_accuracy = model.evaluate(X_test, Y_test)\n#track test results on wandb\nwandb.log({\n    \"test_loss\": test_loss, \n    \"test_accuracy\": test_accuracy\n})","metadata":{"tags":[],"cell_id":"1b8a76b770bc463d824d390118c60aee","source_hash":"29bc63e2","execution_start":1667680634458,"execution_millis":1489,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":" 28/313 [=>............................] - ETA: 0s - loss: 0.2786 - accuracy: 0.9219 /shared-libs/python3.9/py/lib/python3.9/site-packages/keras/backend.py:5582: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n  output, from_logits = _get_logits(\n313/313 [==============================] - 1s 2ms/step - loss: 0.2830 - accuracy: 0.9272\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=ba4822a4-198a-4cdb-8280-0ca8d044b999' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"tags":[],"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"orig_nbformat":2,"deepnote_full_width":true,"deepnote_notebook_id":"911cbcbf89b04f52bc27c20a6fbc2629","deepnote_execution_queue":[]}}