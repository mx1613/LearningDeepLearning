{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"faeffcb8e5df4ac98fdfb9f22f10b516","deepnote_cell_type":"text-cell-h1","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["# Train a NN on the MNIST dataset"]},{"cell_type":"markdown","metadata":{"cell_id":"6ce059d06202442da10a33ff93017ea1","deepnote_cell_type":"markdown","tags":[]},"source":["The MNIST dataset is a collection of hand-written digits, labelled with their corresponding true digit representation. We want to train a MLP (very simple feedforward or sequential network), to recognize hand-written digits. \n","![Picture title](https://upload.wikimedia.org/wikipedia/commons/thumb/2/27/MnistExamples.png/320px-MnistExamples.png)\n"]},{"cell_type":"markdown","metadata":{"cell_id":"5b800454-c2af-4d4b-a962-c417a5b221b0","deepnote_cell_type":"text-cell-h2","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["## Import libraries and define symbolic constants"]},{"cell_type":"markdown","metadata":{"cell_id":"fb73c203820d45bbbde320591d2a9da6","deepnote_cell_type":"text-cell-h3","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["### Install wandb to keep track of model performance"]},{"cell_type":"code","execution_count":1,"metadata":{"cell_id":"1e0d9e9097d5458fa3598a2a6b336ad8","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":4699,"execution_start":1667660925102,"source_hash":"10f68b6d","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: wandb in /root/venv/lib/python3.9/site-packages (0.13.5)\n","Requirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from wandb) (3.19.6)\n","Requirement already satisfied: shortuuid>=0.5.0 in /root/venv/lib/python3.9/site-packages (from wandb) (1.0.9)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /root/venv/lib/python3.9/site-packages (from wandb) (1.10.1)\n","Requirement already satisfied: requests<3,>=2.0.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from wandb) (2.28.1)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from wandb) (8.1.3)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /root/venv/lib/python3.9/site-packages (from wandb) (0.4.0)\n","Requirement already satisfied: setuptools in /root/venv/lib/python3.9/site-packages (from wandb) (58.1.0)\n","Requirement already satisfied: promise<3,>=2.0 in /root/venv/lib/python3.9/site-packages (from wandb) (2.3)\n","Requirement already satisfied: setproctitle in /root/venv/lib/python3.9/site-packages (from wandb) (1.3.2)\n","Requirement already satisfied: GitPython>=1.0.0 in /root/venv/lib/python3.9/site-packages (from wandb) (3.1.29)\n","Requirement already satisfied: psutil>=5.0.0 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from wandb) (5.9.3)\n","Requirement already satisfied: PyYAML in /root/venv/lib/python3.9/site-packages (from wandb) (6.0)\n","Requirement already satisfied: six>=1.13.0 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from wandb) (1.16.0)\n","Requirement already satisfied: pathtools in /root/venv/lib/python3.9/site-packages (from wandb) (0.1.2)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /root/venv/lib/python3.9/site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n","Requirement already satisfied: charset-normalizer<3,>=2 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2.1.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2022.9.24)\n","Requirement already satisfied: idna<4,>=2.5 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (1.26.12)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /root/venv/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n","\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3 is available.\n","You should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}],"source":["!pip install --upgrade wandb\n","!wandb login WANDB_KEY"]},{"cell_type":"markdown","metadata":{"cell_id":"57c1e36168e6420d9538c7ab041c488d","deepnote_cell_type":"text-cell-h3","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["### Import and initialize parameters"]},{"cell_type":"code","execution_count":2,"metadata":{"cell_id":"e1133e5b12f5461c8b25a1e2a634142c","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":5727,"execution_start":1667660929807,"is_output_hidden":false,"source_hash":"20a7913c","tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-11-05 15:08:49.813763: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-11-05 15:08:49.928068: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2022-11-05 15:08:49.932949: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n","2022-11-05 15:08:49.932967: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n","2022-11-05 15:08:49.955979: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2022-11-05 15:08:50.964728: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n","2022-11-05 15:08:50.964787: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n","2022-11-05 15:08:50.964793: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpicklerick\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["Tracking run with wandb version 0.13.5"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/work/wandb/run-20221105_150854-3s9o3tse</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href=\"https://wandb.ai/picklerick/mnist-nn/runs/3s9o3tse\" target=\"_blank\">deft-flower-18</a></strong> to <a href=\"https://wandb.ai/picklerick/mnist-nn\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["import tensorflow as tf\n","import numpy as np\n","from tensorflow import keras\n","\n","import wandb\n","from wandb.keras import WandbCallback\n","\n","wandb.init(project=\"digit-recognition\")\n","\n","EPOCHS = 50  # this is how many times re-train the model, each time optimizing its weight and biases\n","BATCH_SIZE = 64 # this is the number of instances we take from the training set before running the optimizer\n","VERBOSE = 1 # make it loud\n","NB_CLASSES = 10 # we have 10 classes in our dataset, hence 10 neurons in the last layer\n","N_HIDDEN = 128 # neurons in hidden layer\n","VALIDATION_SPLIT = 0.2 #leave 20% of the training set out for validation (accuracy, to avoid overfitting)\n","RESHAPED = 784 # reshape the image from a 28x28 matrix to a vector or 784 elements\n","DROPOUT = 0.3 # portion of dropout values in the network  \n","ACTIVATION_FUNCTION_HIDDEN = 'relu' # activation function for the hidden layers\n","ACTIVATION_FUNCTION_FINAL = 'softmax' # activation function for the output layer \n","OPTIMIZER = 'SGD' # optimizer, this is how we search for the minimum in the loss function\n","LOSS_FUNCTION = 'categorical_crossentropy' #loss function, this is what is otimized\n","METRICS = ['accuracy'] #Our metrics, used to make sure we don't overfit. Computed also on the test set \n","\n","wandb.config = {\n","  \"epochs\": EPOCHS,\n","  \"batch_size\": BATCH_SIZE, \n","  \"n_hidden\": N_HIDDEN,\n","  \"validation_split\": VALIDATION_SPLIT,\n","  'activation_funciton_hidden': ACTIVATION_FUNCTION_HIDDEN,\n","  'activation_funciton_final': ACTIVATION_FUNCTION_FINAL,\n","  'optimizer': OPTIMIZER,\n","  'loss_function': LOSS_FUNCTION,\n","  'metric': METRICS,\n","}\n"]},{"cell_type":"markdown","metadata":{"cell_id":"2f8f46219af348e59d8467ae446c8492","deepnote_cell_type":"text-cell-h2","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["## Load demo dataset from Keras\n"]},{"cell_type":"code","execution_count":3,"metadata":{"cell_id":"afbe7902cca14c388b4a235e182f55a9","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":238,"execution_start":1667660935088,"source_hash":"24f9ab52","tags":[]},"outputs":[],"source":["mnist = keras.datasets.mnist\n","(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"]},{"cell_type":"markdown","metadata":{"cell_id":"f4bf2c4b826343a7be07658c5d616055","deepnote_cell_type":"text-cell-h2","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["## Reshape data and encode labels (one-hot)"]},{"cell_type":"code","execution_count":4,"metadata":{"cell_id":"0a3f72cafb2b4459931ae41f76c099e7","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":71,"execution_start":1667660935329,"source_hash":"7c1b7882","tags":[]},"outputs":[],"source":["X_train = X_train.reshape(60000, RESHAPED).astype(\"float32\")/255\n","X_test = X_test.reshape(10000, RESHAPED).astype(\"float32\")/255\n","\n","# use a One-shot representaiton for the digits\n","Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES)\n","Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)"]},{"cell_type":"markdown","metadata":{"cell_id":"a0d35c151cec42078dde5692ac2846d8","deepnote_cell_type":"text-cell-h2","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["## Build the model"]},{"cell_type":"markdown","metadata":{"cell_id":"b3d4dc4f4fbb4981bcf07582c8521d39","deepnote_cell_type":"text-cell-bullet","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["- The model will be dense, meaning that all neurons at layer L take as inputs all the output of all neurons at layer L-1."]},{"cell_type":"markdown","metadata":{"cell_id":"cc765304-ae7c-4c6e-808b-26ce94408797","deepnote_cell_type":"text-cell-bullet","formattedRanges":[{"fromCodePoint":96,"ranges":[],"toCodePoint":101,"type":"link","url":"https://deepai.org/machine-learning-glossary-and-terms/softmax-layer"}],"is_collapsed":false,"tags":[]},"source":["- The model will use softmax as activation function. The softmax function if very nicely describe here "]},{"cell_type":"code","execution_count":5,"metadata":{"cell_id":"6e931b8266574688a9f4ecddbd1b9922","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":134,"execution_start":1667660935402,"source_hash":"bc34cea9","tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-11-05 15:08:55.405135: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n","2022-11-05 15:08:55.405174: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n","2022-11-05 15:08:55.405191: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (p-ba4822a4-198a-4cdb-8280-0ca8d044b999): /proc/driver/nvidia/version does not exist\n","2022-11-05 15:08:55.405521: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["model = tf.keras.models.Sequential()\n","\n","model.add(\n","    keras.layers.Dense(\n","    N_HIDDEN,\n","    input_shape =(RESHAPED,),\n","    name='dense_layer', \n","    activation=ACTIVATION_FUNCTION_HIDDEN,\n","    kernel_regularizer=keras.regularizers.L2(0.01),\n","    activity_regularizer=keras.regularizers.L2(0.01)\n","    )\n",")\n","model.add(keras.layers.Dropout(DROPOUT))\n","model.add(\n","    keras.layers.Dense(\n","    N_HIDDEN,\n","    name='dense_layer_2', \n","    activation=ACTIVATION_FUNCTION_HIDDEN,\n","    kernel_regularizer=keras.regularizers.L2(0.01),\n","    activity_regularizer=keras.regularizers.L2(0.01)   \n","    )\n",")\n","model.add(keras.layers.Dropout(DROPOUT))\n","model.add(\n","    keras.layers.Dense(\n","    NB_CLASSES,\n","    name='dense_layer_3', \n","    activation=ACTIVATION_FUNCTION_FINAL,\n","    kernel_regularizer=keras.regularizers.L2(0.01),\n","    activity_regularizer=keras.regularizers.L2(0.01) \n","    )\n",")"]},{"cell_type":"markdown","metadata":{"cell_id":"6241b2ea9c564a19bf140c80f82e5f91","deepnote_cell_type":"text-cell-h2","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["## Compile the model"]},{"cell_type":"markdown","metadata":{"cell_id":"2690f8899f85472cb2062310eb62d955","deepnote_cell_type":"text-cell-bullet","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["- We use stochastic gradient descent"]},{"cell_type":"markdown","metadata":{"cell_id":"e306bc2f-0980-4d66-af04-6c46887dee14","deepnote_cell_type":"text-cell-bullet","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["- The loss function is categorical cross-entropy, this is particularly well-suited for multi-class problems with a one-hot encoding "]},{"cell_type":"markdown","metadata":{"cell_id":"886ec107-938e-4725-8769-0b5429189e90","deepnote_cell_type":"text-cell-bullet","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["- We use accuracy to evaluate the performance of the model"]},{"cell_type":"code","execution_count":6,"metadata":{"cell_id":"e286b1fc408847a19ac444d427ad3591","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":5,"execution_start":1667660935523,"source_hash":"c27cdea0","tags":[]},"outputs":[],"source":["model.compile(\n","    optimizer=OPTIMIZER,\n","    loss=LOSS_FUNCTION,\n","    metrics=METRICS\n",")"]},{"cell_type":"markdown","metadata":{"cell_id":"01166b9e952b42298997bd920e423421","deepnote_cell_type":"text-cell-h2","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["## Train the model"]},{"cell_type":"markdown","metadata":{"cell_id":"c8868ddf446a4614a098f38ce9f106b3","deepnote_cell_type":"text-cell-p","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["We are now ready to train the model. We need to define the number of epochs and the batch size. "]},{"cell_type":"markdown","metadata":{"cell_id":"d11528d9-7741-42c7-8750-6d13a00a0004","deepnote_cell_type":"text-cell-bullet","formattedRanges":[{"fromCodePoint":0,"marks":{"code":true},"toCodePoint":7,"type":"marks"}],"is_collapsed":false,"tags":[]},"source":["- Epochs are the number of times the model is exposed to the training dataset. Each time, it will run the optimizer (SGD) and try to minimize the loss function. "]},{"cell_type":"markdown","metadata":{"cell_id":"672b8edf-c2ea-4e8e-b8bc-8f60e31ef234","deepnote_cell_type":"text-cell-bullet","formattedRanges":[{"fromCodePoint":0,"marks":{"code":true},"toCodePoint":10,"type":"marks"}],"is_collapsed":false,"tags":[]},"source":["- Batch_size is the number of instances that the optimizer observes before tuning the weights and biases. There are many batches per epoch."]},{"cell_type":"markdown","metadata":{"cell_id":"c9ca5325-ec41-4841-be96-8e51d81010c3","deepnote_cell_type":"text-cell-bullet","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["- We split the training data in an 80% training and 20% validation per epoch. The validation set is used to compute the metric and tune hyperparameters, to avoid overfitting."]},{"cell_type":"markdown","metadata":{"cell_id":"873cb8e5-b2cf-4749-86f7-c5c660aff465","deepnote_cell_type":"text-cell-bullet","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["- We add early stopping, on the loss function on the validation set, with a patience of N epoch. This will stop the optimization if the loss function does not go down for N  consecutive epochs. "]},{"cell_type":"code","execution_count":7,"metadata":{"cell_id":"fa730a22ee2d4b4ea542c39d3244b375","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":173402,"execution_start":1667660935535,"source_hash":"f150c1c8","tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n","Epoch 1/50\n","750/750 [==============================] - ETA: 0s - loss: 4.9690 - accuracy: 0.5605INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 5s 6ms/step - loss: 4.9690 - accuracy: 0.5605 - val_loss: 3.9941 - val_accuracy: 0.8234\n","Epoch 2/50\n","732/750 [============================>.] - ETA: 0s - loss: 3.6512 - accuracy: 0.7890INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 4s 5ms/step - loss: 3.6413 - accuracy: 0.7894 - val_loss: 3.0789 - val_accuracy: 0.8847\n","Epoch 3/50\n","747/750 [============================>.] - ETA: 0s - loss: 2.9175 - accuracy: 0.8419INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 4s 5ms/step - loss: 2.9169 - accuracy: 0.8418 - val_loss: 2.5099 - val_accuracy: 0.9003\n","Epoch 4/50\n","747/750 [============================>.] - ETA: 0s - loss: 2.4300 - accuracy: 0.8648INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 4s 5ms/step - loss: 2.4292 - accuracy: 0.8648 - val_loss: 2.1162 - val_accuracy: 0.9088\n","Epoch 5/50\n","729/750 [============================>.] - ETA: 0s - loss: 2.0888 - accuracy: 0.8766INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 4s 5ms/step - loss: 2.0858 - accuracy: 0.8761 - val_loss: 1.8349 - val_accuracy: 0.9143\n","Epoch 6/50\n","727/750 [============================>.] - ETA: 0s - loss: 1.8409 - accuracy: 0.8839INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 4s 5ms/step - loss: 1.8384 - accuracy: 0.8838 - val_loss: 1.6295 - val_accuracy: 0.9158\n","Epoch 7/50\n","747/750 [============================>.] - ETA: 0s - loss: 1.6589 - accuracy: 0.8882INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 4s 5ms/step - loss: 1.6585 - accuracy: 0.8882 - val_loss: 1.4783 - val_accuracy: 0.9185\n","Epoch 8/50\n","743/750 [============================>.] - ETA: 0s - loss: 1.5254 - accuracy: 0.8910INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 3s 5ms/step - loss: 1.5250 - accuracy: 0.8910 - val_loss: 1.3701 - val_accuracy: 0.9193\n","Epoch 9/50\n","746/750 [============================>.] - ETA: 0s - loss: 1.4269 - accuracy: 0.8918INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 4s 5ms/step - loss: 1.4267 - accuracy: 0.8918 - val_loss: 1.2885 - val_accuracy: 0.9216\n","Epoch 10/50\n","748/750 [============================>.] - ETA: 0s - loss: 1.3526 - accuracy: 0.8954INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 4s 5ms/step - loss: 1.3526 - accuracy: 0.8954 - val_loss: 1.2287 - val_accuracy: 0.9208\n","Epoch 11/50\n","747/750 [============================>.] - ETA: 0s - loss: 1.2992 - accuracy: 0.8981INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 4s 5ms/step - loss: 1.2991 - accuracy: 0.8982 - val_loss: 1.1845 - val_accuracy: 0.9222\n","Epoch 12/50\n","720/750 [===========================>..] - ETA: 0s - loss: 1.2601 - accuracy: 0.8984INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 4s 5ms/step - loss: 1.2595 - accuracy: 0.8985 - val_loss: 1.1505 - val_accuracy: 0.9237\n","Epoch 13/50\n","729/750 [============================>.] - ETA: 0s - loss: 1.2291 - accuracy: 0.9008INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 3s 5ms/step - loss: 1.2290 - accuracy: 0.9006 - val_loss: 1.1272 - val_accuracy: 0.9244\n","Epoch 14/50\n","739/750 [============================>.] - ETA: 0s - loss: 1.2069 - accuracy: 0.9005INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 4s 5ms/step - loss: 1.2060 - accuracy: 0.9010 - val_loss: 1.1089 - val_accuracy: 0.9250\n","Epoch 15/50\n","739/750 [============================>.] - ETA: 0s - loss: 1.1890 - accuracy: 0.9015INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 4s 5ms/step - loss: 1.1885 - accuracy: 0.9016 - val_loss: 1.0937 - val_accuracy: 0.9268\n","Epoch 16/50\n","727/750 [============================>.] - ETA: 0s - loss: 1.1764 - accuracy: 0.9033INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 4s 5ms/step - loss: 1.1761 - accuracy: 0.9033 - val_loss: 1.0837 - val_accuracy: 0.9260\n","Epoch 17/50\n","741/750 [============================>.] - ETA: 0s - loss: 1.1655 - accuracy: 0.9022INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 4s 5ms/step - loss: 1.1653 - accuracy: 0.9022 - val_loss: 1.0756 - val_accuracy: 0.9258\n","Epoch 18/50\n","723/750 [===========================>..] - ETA: 0s - loss: 1.1589 - accuracy: 0.9035INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 4s 5ms/step - loss: 1.1581 - accuracy: 0.9036 - val_loss: 1.0682 - val_accuracy: 0.9268\n","Epoch 19/50\n","738/750 [============================>.] - ETA: 0s - loss: 1.1512 - accuracy: 0.9041INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 3s 5ms/step - loss: 1.1514 - accuracy: 0.9038 - val_loss: 1.0647 - val_accuracy: 0.9271\n","Epoch 20/50\n","736/750 [============================>.] - ETA: 0s - loss: 1.1467 - accuracy: 0.9040INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 4s 5ms/step - loss: 1.1471 - accuracy: 0.9037 - val_loss: 1.0598 - val_accuracy: 0.9271\n","Epoch 21/50\n","723/750 [===========================>..] - ETA: 0s - loss: 1.1435 - accuracy: 0.9052INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 4s 5ms/step - loss: 1.1436 - accuracy: 0.9051 - val_loss: 1.0572 - val_accuracy: 0.9274\n","Epoch 22/50\n","734/750 [============================>.] - ETA: 0s - loss: 1.1397 - accuracy: 0.9064INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 4s 5ms/step - loss: 1.1390 - accuracy: 0.9068 - val_loss: 1.0540 - val_accuracy: 0.9273\n","Epoch 23/50\n","744/750 [============================>.] - ETA: 0s - loss: 1.1357 - accuracy: 0.9066INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 4s 5ms/step - loss: 1.1360 - accuracy: 0.9063 - val_loss: 1.0531 - val_accuracy: 0.9283\n","Epoch 24/50\n","750/750 [==============================] - ETA: 0s - loss: 1.1336 - accuracy: 0.9066INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 4s 5ms/step - loss: 1.1336 - accuracy: 0.9066 - val_loss: 1.0512 - val_accuracy: 0.9282\n","Epoch 25/50\n","725/750 [============================>.] - ETA: 0s - loss: 1.1326 - accuracy: 0.9059INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 4s 5ms/step - loss: 1.1328 - accuracy: 0.9059 - val_loss: 1.0489 - val_accuracy: 0.9279\n","Epoch 26/50\n","746/750 [============================>.] - ETA: 0s - loss: 1.1299 - accuracy: 0.9077INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 4s 5ms/step - loss: 1.1297 - accuracy: 0.9080 - val_loss: 1.0472 - val_accuracy: 0.9282\n","Epoch 27/50\n","744/750 [============================>.] - ETA: 0s - loss: 1.1294 - accuracy: 0.9072INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 4s 5ms/step - loss: 1.1297 - accuracy: 0.9072 - val_loss: 1.0467 - val_accuracy: 0.9283\n","Epoch 28/50\n","731/750 [============================>.] - ETA: 0s - loss: 1.1277 - accuracy: 0.9075INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 4s 5ms/step - loss: 1.1279 - accuracy: 0.9074 - val_loss: 1.0451 - val_accuracy: 0.9277\n","Epoch 29/50\n","722/750 [===========================>..] - ETA: 0s - loss: 1.1273 - accuracy: 0.9075INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 4s 5ms/step - loss: 1.1277 - accuracy: 0.9073 - val_loss: 1.0444 - val_accuracy: 0.9283\n","Epoch 30/50\n","741/750 [============================>.] - ETA: 0s - loss: 1.1257 - accuracy: 0.9073INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 4s 5ms/step - loss: 1.1259 - accuracy: 0.9071 - val_loss: 1.0441 - val_accuracy: 0.9277\n","Epoch 31/50\n","749/750 [============================>.] - ETA: 0s - loss: 1.1247 - accuracy: 0.9077INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 4s 5ms/step - loss: 1.1246 - accuracy: 0.9077 - val_loss: 1.0431 - val_accuracy: 0.9284\n","Epoch 32/50\n","746/750 [============================>.] - ETA: 0s - loss: 1.1232 - accuracy: 0.9079INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 4s 5ms/step - loss: 1.1229 - accuracy: 0.9080 - val_loss: 1.0427 - val_accuracy: 0.9281\n","Epoch 33/50\n","740/750 [============================>.] - ETA: 0s - loss: 1.1227 - accuracy: 0.9079INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 4s 5ms/step - loss: 1.1230 - accuracy: 0.9077 - val_loss: 1.0414 - val_accuracy: 0.9289\n","Epoch 34/50\n","750/750 [==============================] - 3s 4ms/step - loss: 1.1223 - accuracy: 0.9079 - val_loss: 1.0422 - val_accuracy: 0.9308\n","Epoch 35/50\n","735/750 [============================>.] - ETA: 0s - loss: 1.1211 - accuracy: 0.9084INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 4s 5ms/step - loss: 1.1211 - accuracy: 0.9082 - val_loss: 1.0410 - val_accuracy: 0.9289\n","Epoch 36/50\n","750/750 [==============================] - 3s 4ms/step - loss: 1.1195 - accuracy: 0.9085 - val_loss: 1.0415 - val_accuracy: 0.9289\n","Epoch 37/50\n","741/750 [============================>.] - ETA: 0s - loss: 1.1191 - accuracy: 0.9081INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 3s 5ms/step - loss: 1.1194 - accuracy: 0.9079 - val_loss: 1.0398 - val_accuracy: 0.9291\n","Epoch 38/50\n","750/750 [==============================] - ETA: 0s - loss: 1.1173 - accuracy: 0.9092INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 3s 5ms/step - loss: 1.1173 - accuracy: 0.9092 - val_loss: 1.0392 - val_accuracy: 0.9297\n","Epoch 39/50\n","737/750 [============================>.] - ETA: 0s - loss: 1.1187 - accuracy: 0.9082INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 4s 5ms/step - loss: 1.1180 - accuracy: 0.9086 - val_loss: 1.0384 - val_accuracy: 0.9293\n","Epoch 40/50\n","750/750 [==============================] - 3s 4ms/step - loss: 1.1176 - accuracy: 0.9086 - val_loss: 1.0384 - val_accuracy: 0.9295\n","Epoch 41/50\n","723/750 [===========================>..] - ETA: 0s - loss: 1.1172 - accuracy: 0.9088INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 3s 5ms/step - loss: 1.1177 - accuracy: 0.9086 - val_loss: 1.0369 - val_accuracy: 0.9302\n","Epoch 42/50\n","750/750 [==============================] - 3s 4ms/step - loss: 1.1162 - accuracy: 0.9098 - val_loss: 1.0383 - val_accuracy: 0.9287\n","Epoch 43/50\n","750/750 [==============================] - 3s 4ms/step - loss: 1.1139 - accuracy: 0.9101 - val_loss: 1.0375 - val_accuracy: 0.9299\n","Epoch 44/50\n","750/750 [==============================] - 3s 3ms/step - loss: 1.1156 - accuracy: 0.9097 - val_loss: 1.0376 - val_accuracy: 0.9294\n","Epoch 45/50\n","718/750 [===========================>..] - ETA: 0s - loss: 1.1156 - accuracy: 0.9100INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 4s 5ms/step - loss: 1.1164 - accuracy: 0.9096 - val_loss: 1.0368 - val_accuracy: 0.9302\n","Epoch 46/50\n","726/750 [============================>.] - ETA: 0s - loss: 1.1122 - accuracy: 0.9107INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 4s 5ms/step - loss: 1.1118 - accuracy: 0.9109 - val_loss: 1.0368 - val_accuracy: 0.9296\n","Epoch 47/50\n","736/750 [============================>.] - ETA: 0s - loss: 1.1140 - accuracy: 0.9098INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 4s 5ms/step - loss: 1.1140 - accuracy: 0.9099 - val_loss: 1.0349 - val_accuracy: 0.9300\n","Epoch 48/50\n","750/750 [==============================] - 3s 4ms/step - loss: 1.1140 - accuracy: 0.9098 - val_loss: 1.0357 - val_accuracy: 0.9313\n","Epoch 49/50\n","740/750 [============================>.] - ETA: 0s - loss: 1.1128 - accuracy: 0.9109INFO:tensorflow:Assets written to: /work/wandb/run-20221105_150854-3s9o3tse/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_150854-3s9o3tse/files/model-best)... Done. 0.0s\n","750/750 [==============================] - 3s 5ms/step - loss: 1.1130 - accuracy: 0.9109 - val_loss: 1.0347 - val_accuracy: 0.9308\n","Epoch 50/50\n","750/750 [==============================] - 3s 4ms/step - loss: 1.1140 - accuracy: 0.9095 - val_loss: 1.0362 - val_accuracy: 0.9307\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7f256864cb50>"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["model.fit(\n","    X_train, \n","    Y_train, \n","    batch_size=BATCH_SIZE,\n","    epochs=EPOCHS,\n","    verbose=VERBOSE,\n","    validation_split=VALIDATION_SPLIT,\n","    callbacks=[\n","        WandbCallback(),\n","        ],\n","    )"]},{"cell_type":"markdown","metadata":{"cell_id":"05b13eda75594fae9543f5752c6250f0","deepnote_cell_type":"text-cell-h2","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["## Test the model on unseen data"]},{"cell_type":"code","execution_count":8,"metadata":{"cell_id":"dcf5027fbf3f411baa028d204f5143f4","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":643,"execution_start":1667661108989,"source_hash":"29bc63e2","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["313/313 [==============================] - 1s 2ms/step - loss: 1.0371 - accuracy: 0.9275\n"]}],"source":["test_loss, test_accuracy = model.evaluate(X_test, Y_test)\n","#track test results on wandb\n","wandb.log({\n","    \"test_loss\": test_loss, \n","    \"test_accuracy\": test_accuracy\n","})"]},{"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown","tags":[]},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=ba4822a4-198a-4cdb-8280-0ca8d044b999' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_full_width":true,"deepnote_notebook_id":"e5052b07c473490193ff4cd1e236ae72","language_info":{"name":"python"},"orig_nbformat":2},"nbformat":4,"nbformat_minor":0}
