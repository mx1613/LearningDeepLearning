{"cells":[{"cell_type":"markdown","source":"# Sentiment analysis on the IMDB dataset","metadata":{"tags":[],"cell_id":"0fd2e3f29de046a0b4622ab37218b548","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h1"}},{"cell_type":"markdown","source":"Sentiment analysis on the keras IMDB dataset. The dataset cointains 50k text reviews in English, labelled with a thumbs up or thumbs down label. We want to be able to predict if the review is positive or negative from the text. \n\n![Picture title](http://flovv.github.io/figures/post25/imdb_classification.png)\n","metadata":{"tags":[],"cell_id":"bc9f63e5f210462abf4a131bfb3e57f6","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"## Import libraries and define symbolic constants","metadata":{"tags":[],"cell_id":"f132718fb14b47a49814b75bed40d6a1","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"markdown","source":"### Install wandb to keep track of model performance","metadata":{"tags":[],"cell_id":"4268a32575894975a4c9d8700ffee96a","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h3"}},{"cell_type":"code","source":"!pip install --upgrade wandb\n!wandb login ff97f4ffa6b4b35ec56fc229fc572b0ba72ac1fb","metadata":{"tags":[],"cell_id":"c252b24edfa34f0985f0435d97c0170b","source_hash":"10f68b6d","execution_start":1667664685331,"execution_millis":5184,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /root/venv/lib/python3.9/site-packages (0.13.5)\nRequirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from wandb) (3.19.6)\nRequirement already satisfied: GitPython>=1.0.0 in /root/venv/lib/python3.9/site-packages (from wandb) (3.1.29)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /root/venv/lib/python3.9/site-packages (from wandb) (1.10.1)\nRequirement already satisfied: pathtools in /root/venv/lib/python3.9/site-packages (from wandb) (0.1.2)\nRequirement already satisfied: setuptools in /root/venv/lib/python3.9/site-packages (from wandb) (58.1.0)\nRequirement already satisfied: requests<3,>=2.0.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from wandb) (2.28.1)\nRequirement already satisfied: six>=1.13.0 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from wandb) (1.16.0)\nRequirement already satisfied: psutil>=5.0.0 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /root/venv/lib/python3.9/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: shortuuid>=0.5.0 in /root/venv/lib/python3.9/site-packages (from wandb) (1.0.9)\nRequirement already satisfied: setproctitle in /root/venv/lib/python3.9/site-packages (from wandb) (1.3.2)\nRequirement already satisfied: promise<3,>=2.0 in /root/venv/lib/python3.9/site-packages (from wandb) (2.3)\nRequirement already satisfied: Click!=8.0.0,>=7.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from wandb) (8.1.3)\nRequirement already satisfied: PyYAML in /root/venv/lib/python3.9/site-packages (from wandb) (6.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /root/venv/lib/python3.9/site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\nRequirement already satisfied: charset-normalizer<3,>=2 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2.1.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (1.26.12)\nRequirement already satisfied: idna<4,>=2.5 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2022.9.24)\nRequirement already satisfied: smmap<6,>=3.0.1 in /root/venv/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3 is available.\nYou should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n\u001b[0m\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"### Import and initialize parameters","metadata":{"tags":[],"cell_id":"a43d7dcaebd04a978763b0b2cf90d742","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h3"}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras import datasets\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import models\nfrom tensorflow.keras import preprocessing\n\nimport wandb\nfrom wandb.keras import WandbCallback\n\nwandb.init(project=\"sentiment-analysis\")\n\nEPOCHS = 20  # this is how many times re-train the model, each time optimizing its weight and biases\nBATCH_SIZE = 500 # this is the number of instances we take from the training set before running the optimizer\nVERBOSE = 1 # make it loud\nN_HIDDEN = 128 # neurons in hidden layer\nDROPOUT = 0.3 # portion of dropout values in the network  \n\nACTIVATION_FUNCTION_HIDDEN = 'relu' # activation function for the hidden layers\nACTIVATION_FUNCTION_FINAL = 'sigmoid' # activation function for the output layer \nOPTIMIZER = 'adam' # optimizer, this is how we search for the minimum in the loss function\nLOSS_FUNCTION = 'binary_crossentropy' #loss function, this is what is otimized\n\nMETRICS = ['accuracy'] #Our metrics, used to make sure we don't overfit. Computed also on the test set \n\nmax_len = 200\nn_words = 10000\ndim_embedding = 256\n\nwandb.config = {\n  \"epochs\": EPOCHS,\n  \"batch_size\": BATCH_SIZE, \n  \"n_hidden\": N_HIDDEN,\n  'activation_funciton_hidden': ACTIVATION_FUNCTION_HIDDEN,\n  'activation_funciton_final': ACTIVATION_FUNCTION_FINAL,\n  'optimizer': OPTIMIZER,\n  'loss_function': LOSS_FUNCTION,\n  'metric': METRICS,\n}\n","metadata":{"tags":[],"cell_id":"f6c6e141d44348e3bdb7e6035d47ad27","source_hash":"b779d2a6","execution_start":1667664690525,"execution_millis":5803,"is_output_hidden":false,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stderr","text":"2022-11-05 16:11:30.530909: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-11-05 16:11:30.652731: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n2022-11-05 16:11:30.657834: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2022-11-05 16:11:30.657854: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n2022-11-05 16:11:30.690652: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2022-11-05 16:11:31.802168: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n2022-11-05 16:11:31.802289: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n2022-11-05 16:11:31.802298: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\nFailed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpicklerick\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.13.5"},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/work/wandb/run-20221105_161135-3r1q2yz1</code>"},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href=\"https://wandb.ai/picklerick/sentiment-analysis/runs/3r1q2yz1\" target=\"_blank\">restful-tree-8</a></strong> to <a href=\"https://wandb.ai/picklerick/sentiment-analysis\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"},"metadata":{},"output_type":"display_data"}],"execution_count":null},{"cell_type":"markdown","source":"## Load demo dataset from Keras\r","metadata":{"tags":[],"cell_id":"39ff42f5bb09425a824fc95f5d26fa52","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"code","source":"def load_data():\n    #load dataset from keras\n    (X_train, Y_train), (X_test, Y_test) = datasets.imdb.load_data(num_words=n_words)\n    #pad data\n    X_train = preprocessing.sequence.pad_sequences(X_train, maxlen=max_len)\n    X_test = preprocessing.sequence.pad_sequences(X_test, maxlen=max_len)\n    return (X_train, Y_train), (X_test, Y_test)\n\n(X_train, Y_train), (X_test, Y_test) = load_data()\nprint(X_test)","metadata":{"tags":[],"cell_id":"0fbfe3716b384becb1d0cbcca4bd0b00","source_hash":"6ea1c5e9","execution_start":1667665693387,"execution_millis":4543,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"[[   0    0    0 ...   14    6  717]\n [1987    2   45 ...  125    4 3077]\n [4468  189    4 ...    9   57  975]\n ...\n [   0    0    0 ...   21  846 5518]\n [   0    0    0 ... 2302    7  470]\n [   0    0    0 ...   34 2005 2643]]\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"## Build the model","metadata":{"tags":[],"cell_id":"a1756330b0a34906a55287ac9aeb31ed","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"markdown","source":"- We use an embedding layer as input, this maps words to a more dense feature space","metadata":{"tags":[],"cell_id":"4dfa001a6fb1411cac005d4bb5b06c1a","is_collapsed":false,"formattedRanges":[{"type":"marks","marks":{"code":true},"toCodePoint":20,"fromCodePoint":10}],"deepnote_cell_type":"text-cell-bullet"}},{"cell_type":"markdown","source":"- We then use a maxpooling layer, that takes the may value from of either feature vector across the n_words","metadata":{"tags":[],"cell_id":"19ce2f94-c9f9-46ef-9239-f036da212a7a","is_collapsed":false,"formattedRanges":[{"type":"marks","marks":{"code":true},"toCodePoint":25,"fromCodePoint":14}],"deepnote_cell_type":"text-cell-bullet"}},{"cell_type":"markdown","source":"- We then have two dense layers.","metadata":{"tags":[],"cell_id":"5c5f6f0f-4df5-4608-9e33-3196f991a177","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-bullet"}},{"cell_type":"markdown","source":"- The last layer is a single neuron with a sigmoid activation function, which we will interpret as a probability that the review is favorable","metadata":{"tags":[],"cell_id":"eb18779e-92a7-4006-89cb-2007b0b616ce","is_collapsed":false,"formattedRanges":[{"type":"marks","marks":{"code":true},"toCodePoint":48,"fromCodePoint":41},{"url":"https://deepai.org/machine-learning-glossary-and-terms/softmax-layer","type":"link","ranges":[],"toCodePoint":139,"fromCodePoint":139}],"deepnote_cell_type":"text-cell-bullet"}},{"cell_type":"code","source":"def build_model():\n    model = models.Sequential()\n\n    model.add(\n        layers.Embedding(\n        n_words,\n        dim_embedding,\n        input_length=max_len\n        )\n    )\n    model.add(\n        layers.Dropout(DROPOUT)\n    )\n    model.add(\n        layers.GlobalMaxPooling1D()\n    )\n    model.add(\n        layers.Dense(\n            128,\n            activation = ACTIVATION_FUNCTION_HIDDEN\n        ) \n    )\n    model.add(\n        layers.Dropout(DROPOUT+0.2)\n    )    \n    model.add(\n        layers.Dense(\n            1,\n            activation = ACTIVATION_FUNCTION_FINAL\n        ) \n    )\n\n    return model\n    \nmodel = build_model()\nmodel.summary()","metadata":{"tags":[],"cell_id":"0ff8afdd30514941b2acc1a1ec2f8988","source_hash":"1d3643cc","execution_start":1667664699908,"execution_millis":196,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding (Embedding)       (None, 200, 256)          2560000   \n                                                                 \n dropout (Dropout)           (None, 200, 256)          0         \n                                                                 \n global_max_pooling1d (Globa  (None, 256)              0         \n lMaxPooling1D)                                                  \n                                                                 \n dense (Dense)               (None, 128)               32896     \n                                                                 \n dropout_1 (Dropout)         (None, 128)               0         \n                                                                 \n dense_1 (Dense)             (None, 1)                 129       \n                                                                 \n=================================================================\nTotal params: 2,593,025\nTrainable params: 2,593,025\nNon-trainable params: 0\n_________________________________________________________________\n2022-11-05 16:11:39.907030: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n2022-11-05 16:11:39.907062: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n2022-11-05 16:11:39.907079: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (p-ba4822a4-198a-4cdb-8280-0ca8d044b999): /proc/driver/nvidia/version does not exist\n2022-11-05 16:11:39.907299: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Compile the model","metadata":{"tags":[],"cell_id":"fcc959b6d6ee4987b3c2076f6e6f5838","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"markdown","source":"- We use adam as optimizer","metadata":{"tags":[],"cell_id":"3f79f0770c3044d88565ece8e7b1dca5","is_collapsed":false,"formattedRanges":[{"type":"marks","marks":{"code":true},"toCodePoint":12,"fromCodePoint":7}],"deepnote_cell_type":"text-cell-bullet"}},{"cell_type":"markdown","source":"- The loss function is categorical cross-entropy, this is particularly well-suited for multi-class problems with a one-hot encoding ","metadata":{"tags":[],"cell_id":"e0d88fa0f5ff4344ae1778d6e0c8a5c7","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-bullet"}},{"cell_type":"markdown","source":"- We use accuracy to evaluate the performance of the model","metadata":{"tags":[],"cell_id":"d30cb009030d417385574dffecc3bf77","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-bullet"}},{"cell_type":"code","source":"model.compile(\n    optimizer=OPTIMIZER,\n    loss=LOSS_FUNCTION,\n    metrics=METRICS\n)","metadata":{"tags":[],"cell_id":"f51c903fa2824ec0a794b040dab715d4","source_hash":"c27cdea0","execution_start":1667664700103,"execution_millis":0,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Train the model","metadata":{"tags":[],"cell_id":"8e6796b30a4e42c19ae3032e9200c0de","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"markdown","source":"We are now ready to train the model. We need to define the number of epochs and the batch size. ","metadata":{"tags":[],"cell_id":"bb29293690384a3ca5935360d4b49c4c","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"- Epochs are the number of times the model is exposed to the training dataset. Each time, it will run the optimizer (SGD) and try to minimize the loss function. ","metadata":{"tags":[],"cell_id":"0a0d17b17cfb41ffac857a46b06e9502","is_collapsed":false,"formattedRanges":[{"type":"marks","marks":{"code":true},"toCodePoint":7,"fromCodePoint":0}],"deepnote_cell_type":"text-cell-bullet"}},{"cell_type":"markdown","source":"- Batch_size is the number of instances that the optimizer observes before tuning the weights and biases. There are many batches per epoch.","metadata":{"tags":[],"cell_id":"befe85df6fbd4eeca24fac6a602a3294","is_collapsed":false,"formattedRanges":[{"type":"marks","marks":{"code":true},"toCodePoint":10,"fromCodePoint":0}],"deepnote_cell_type":"text-cell-bullet"}},{"cell_type":"markdown","source":"- We split the training data in an 80% training and 20% validation per epoch. The validation set is used to compute the metric and tune hyperparameters, to avoid overfitting.","metadata":{"tags":[],"cell_id":"b9ad143b41fe41b2a17505a3c19fe047","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-bullet"}},{"cell_type":"markdown","source":"- We add early stopping, on the loss function on the validation set, with a patience of N epoch. This will stop the optimization if the loss function does not go down for N  consecutive epochs. ","metadata":{"tags":[],"cell_id":"f4cc24f36f2146169952a1474abdecae","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-bullet"}},{"cell_type":"code","source":"score = model.fit(\n    X_train,\n    Y_train,\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS,\n    verbose=VERBOSE,\n    validation_data=(X_test, Y_test),\n    callbacks=[WandbCallback()]\n    )","metadata":{"tags":[],"cell_id":"800c6751589d4667a02f3fce4c5df9c0","source_hash":"951e092d","execution_start":1667664700104,"execution_millis":670894,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\nEpoch 1/20\n50/50 [==============================] - ETA: 0s - loss: 0.6751 - accuracy: 0.5890INFO:tensorflow:Assets written to: /work/wandb/run-20221105_161135-3r1q2yz1/files/model-best/assets\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_161135-3r1q2yz1/files/model-best)... Done. 0.1s\n50/50 [==============================] - 34s 671ms/step - loss: 0.6751 - accuracy: 0.5890 - val_loss: 0.6386 - val_accuracy: 0.7696\nEpoch 2/20\n50/50 [==============================] - ETA: 0s - loss: 0.4822 - accuracy: 0.8292INFO:tensorflow:Assets written to: /work/wandb/run-20221105_161135-3r1q2yz1/files/model-best/assets\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_161135-3r1q2yz1/files/model-best)... Done. 0.1s\n50/50 [==============================] - 33s 666ms/step - loss: 0.4822 - accuracy: 0.8292 - val_loss: 0.3779 - val_accuracy: 0.8542\nEpoch 3/20\n50/50 [==============================] - ETA: 0s - loss: 0.2880 - accuracy: 0.8801INFO:tensorflow:Assets written to: /work/wandb/run-20221105_161135-3r1q2yz1/files/model-best/assets\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_161135-3r1q2yz1/files/model-best)... Done. 0.1s\n50/50 [==============================] - 33s 661ms/step - loss: 0.2880 - accuracy: 0.8801 - val_loss: 0.3066 - val_accuracy: 0.8736\nEpoch 4/20\n50/50 [==============================] - ETA: 0s - loss: 0.2202 - accuracy: 0.9138INFO:tensorflow:Assets written to: /work/wandb/run-20221105_161135-3r1q2yz1/files/model-best/assets\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_161135-3r1q2yz1/files/model-best)... Done. 0.2s\n50/50 [==============================] - 33s 659ms/step - loss: 0.2202 - accuracy: 0.9138 - val_loss: 0.2944 - val_accuracy: 0.8755\nEpoch 5/20\n50/50 [==============================] - 32s 644ms/step - loss: 0.1741 - accuracy: 0.9364 - val_loss: 0.2946 - val_accuracy: 0.8737\nEpoch 6/20\n50/50 [==============================] - ETA: 0s - loss: 0.1349 - accuracy: 0.9543INFO:tensorflow:Assets written to: /work/wandb/run-20221105_161135-3r1q2yz1/files/model-best/assets\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_161135-3r1q2yz1/files/model-best)... Done. 0.1s\n50/50 [==============================] - 33s 661ms/step - loss: 0.1349 - accuracy: 0.9543 - val_loss: 0.2924 - val_accuracy: 0.8754\nEpoch 7/20\n50/50 [==============================] - 32s 647ms/step - loss: 0.1025 - accuracy: 0.9678 - val_loss: 0.3063 - val_accuracy: 0.8692\nEpoch 8/20\n50/50 [==============================] - 32s 643ms/step - loss: 0.0776 - accuracy: 0.9773 - val_loss: 0.3224 - val_accuracy: 0.8645\nEpoch 9/20\n50/50 [==============================] - 32s 647ms/step - loss: 0.0583 - accuracy: 0.9839 - val_loss: 0.3379 - val_accuracy: 0.8629\nEpoch 10/20\n50/50 [==============================] - 36s 717ms/step - loss: 0.0433 - accuracy: 0.9890 - val_loss: 0.3562 - val_accuracy: 0.8596\nEpoch 11/20\n50/50 [==============================] - 32s 642ms/step - loss: 0.0321 - accuracy: 0.9930 - val_loss: 0.3727 - val_accuracy: 0.8578\nEpoch 12/20\n50/50 [==============================] - 32s 643ms/step - loss: 0.0250 - accuracy: 0.9947 - val_loss: 0.3898 - val_accuracy: 0.8558\nEpoch 13/20\n50/50 [==============================] - 32s 647ms/step - loss: 0.0187 - accuracy: 0.9963 - val_loss: 0.4103 - val_accuracy: 0.8535\nEpoch 14/20\n50/50 [==============================] - 36s 732ms/step - loss: 0.0154 - accuracy: 0.9971 - val_loss: 0.4261 - val_accuracy: 0.8524\nEpoch 15/20\n50/50 [==============================] - 36s 721ms/step - loss: 0.0127 - accuracy: 0.9974 - val_loss: 0.4418 - val_accuracy: 0.8492\nEpoch 16/20\n50/50 [==============================] - 42s 840ms/step - loss: 0.0102 - accuracy: 0.9988 - val_loss: 0.4495 - val_accuracy: 0.8513\nEpoch 17/20\n50/50 [==============================] - 32s 649ms/step - loss: 0.0088 - accuracy: 0.9988 - val_loss: 0.4672 - val_accuracy: 0.8495\nEpoch 18/20\n50/50 [==============================] - 32s 651ms/step - loss: 0.0077 - accuracy: 0.9988 - val_loss: 0.4730 - val_accuracy: 0.8520\nEpoch 19/20\n50/50 [==============================] - 32s 639ms/step - loss: 0.0064 - accuracy: 0.9990 - val_loss: 0.4898 - val_accuracy: 0.8505\nEpoch 20/20\n50/50 [==============================] - 32s 643ms/step - loss: 0.0052 - accuracy: 0.9994 - val_loss: 0.5046 - val_accuracy: 0.8498\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## Test the model on unseen data","metadata":{"tags":[],"cell_id":"d913a535595f4333be10de48c97348e3","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"code","source":"test_loss, test_accuracy = model.evaluate(X_test, Y_test, batch_size=BATCH_SIZE)\n#track test results on wandb\nwandb.log({\n    \"test_loss\": test_loss, \n    \"test_accuracy\": test_accuracy\n})","metadata":{"tags":[],"cell_id":"8651c6ccef9c406e8c8cff273bd848a5","source_hash":"1d89c494","execution_start":1667665371004,"execution_millis":2358,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"50/50 [==============================] - 2s 41ms/step - loss: 0.5046 - accuracy: 0.8498\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=ba4822a4-198a-4cdb-8280-0ca8d044b999' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"tags":[],"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"orig_nbformat":2,"deepnote_full_width":true,"deepnote_notebook_id":"0c3efa607dff4878a1e27f38a68d86c0","deepnote_execution_queue":[]}}