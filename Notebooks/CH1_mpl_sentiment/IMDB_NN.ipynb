{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"0fd2e3f29de046a0b4622ab37218b548","deepnote_cell_type":"text-cell-h1","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["# Sentiment analysis on the IMDB dataset"]},{"cell_type":"markdown","metadata":{"cell_id":"bc9f63e5f210462abf4a131bfb3e57f6","deepnote_cell_type":"markdown","tags":[]},"source":["Sentiment analysis on the keras IMDB dataset. The dataset cointains 50k text reviews in English, labelled with a thumbs up or thumbs down label. We want to be able to predict if the review is positive or negative from the text. \n","\n","![Picture title](http://flovv.github.io/figures/post25/imdb_classification.png)\n"]},{"cell_type":"markdown","metadata":{"cell_id":"f132718fb14b47a49814b75bed40d6a1","deepnote_cell_type":"text-cell-h2","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["## Import libraries and define symbolic constants"]},{"cell_type":"markdown","metadata":{"cell_id":"4268a32575894975a4c9d8700ffee96a","deepnote_cell_type":"text-cell-h3","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["### Install wandb to keep track of model performance"]},{"cell_type":"code","execution_count":1,"metadata":{"cell_id":"c252b24edfa34f0985f0435d97c0170b","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":5184,"execution_start":1667664685331,"source_hash":"10f68b6d","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: wandb in /root/venv/lib/python3.9/site-packages (0.13.5)\n","Requirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from wandb) (3.19.6)\n","Requirement already satisfied: GitPython>=1.0.0 in /root/venv/lib/python3.9/site-packages (from wandb) (3.1.29)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /root/venv/lib/python3.9/site-packages (from wandb) (1.10.1)\n","Requirement already satisfied: pathtools in /root/venv/lib/python3.9/site-packages (from wandb) (0.1.2)\n","Requirement already satisfied: setuptools in /root/venv/lib/python3.9/site-packages (from wandb) (58.1.0)\n","Requirement already satisfied: requests<3,>=2.0.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from wandb) (2.28.1)\n","Requirement already satisfied: six>=1.13.0 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from wandb) (1.16.0)\n","Requirement already satisfied: psutil>=5.0.0 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from wandb) (5.9.3)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /root/venv/lib/python3.9/site-packages (from wandb) (0.4.0)\n","Requirement already satisfied: shortuuid>=0.5.0 in /root/venv/lib/python3.9/site-packages (from wandb) (1.0.9)\n","Requirement already satisfied: setproctitle in /root/venv/lib/python3.9/site-packages (from wandb) (1.3.2)\n","Requirement already satisfied: promise<3,>=2.0 in /root/venv/lib/python3.9/site-packages (from wandb) (2.3)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from wandb) (8.1.3)\n","Requirement already satisfied: PyYAML in /root/venv/lib/python3.9/site-packages (from wandb) (6.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /root/venv/lib/python3.9/site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n","Requirement already satisfied: charset-normalizer<3,>=2 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2.1.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (1.26.12)\n","Requirement already satisfied: idna<4,>=2.5 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2022.9.24)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /root/venv/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n","\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3 is available.\n","You should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}],"source":["!pip install --upgrade wandb\n","!wandb login WANDB_KEY"]},{"cell_type":"markdown","metadata":{"cell_id":"a43d7dcaebd04a978763b0b2cf90d742","deepnote_cell_type":"text-cell-h3","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["### Import and initialize parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"f6c6e141d44348e3bdb7e6035d47ad27","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":5803,"execution_start":1667664690525,"is_output_hidden":false,"source_hash":"b779d2a6","tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-11-05 16:11:30.530909: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-11-05 16:11:30.652731: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2022-11-05 16:11:30.657834: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n","2022-11-05 16:11:30.657854: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n","2022-11-05 16:11:30.690652: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2022-11-05 16:11:31.802168: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n","2022-11-05 16:11:31.802289: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n","2022-11-05 16:11:31.802298: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpicklerick\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["Tracking run with wandb version 0.13.5"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/work/wandb/run-20221105_161135-3r1q2yz1</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href=\"https://wandb.ai/picklerick/sentiment-analysis/runs/3r1q2yz1\" target=\"_blank\">restful-tree-8</a></strong> to <a href=\"https://wandb.ai/picklerick/sentiment-analysis\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["import tensorflow as tf\n","import numpy as np\n","from tensorflow.keras import datasets\n","from tensorflow.keras import layers\n","from tensorflow.keras import models\n","from tensorflow.keras import preprocessing\n","\n","import wandb\n","from wandb.keras import WandbCallback\n","\n","wandb.init(project=\"sentiment-analysis\")\n","\n","EPOCHS = 20  # this is how many times re-train the model, each time optimizing its weight and biases\n","BATCH_SIZE = 500 # this is the number of instances we take from the training set before running the optimizer\n","VERBOSE = 1 # make it loud\n","N_HIDDEN = 128 # neurons in hidden layer\n","DROPOUT = 0.3 # portion of dropout values in the network  \n","\n","ACTIVATION_FUNCTION_HIDDEN = 'relu' # activation function for the hidden layers\n","ACTIVATION_FUNCTION_FINAL = 'sigmoid' # activation function for the output layer \n","OPTIMIZER = 'adam' # optimizer, this is how we search for the minimum in the loss function\n","LOSS_FUNCTION = 'binary_crossentropy' #loss function, this is what is otimized\n","\n","METRICS = ['accuracy'] #Our metrics, used to make sure we don't overfit. Computed also on the test set \n","\n","max_len = 200\n","n_words = 10000\n","dim_embedding = 256\n","\n","wandb.config = {\n","  \"epochs\": EPOCHS,\n","  \"batch_size\": BATCH_SIZE, \n","  \"n_hidden\": N_HIDDEN,\n","  'activation_funciton_hidden': ACTIVATION_FUNCTION_HIDDEN,\n","  'activation_funciton_final': ACTIVATION_FUNCTION_FINAL,\n","  'optimizer': OPTIMIZER,\n","  'loss_function': LOSS_FUNCTION,\n","  'metric': METRICS,\n","}\n"]},{"cell_type":"markdown","metadata":{"cell_id":"39ff42f5bb09425a824fc95f5d26fa52","deepnote_cell_type":"text-cell-h2","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["## Load demo dataset from Keras\n"]},{"cell_type":"code","execution_count":18,"metadata":{"cell_id":"0fbfe3716b384becb1d0cbcca4bd0b00","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":4543,"execution_start":1667665693387,"source_hash":"6ea1c5e9","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["[[   0    0    0 ...   14    6  717]\n"," [1987    2   45 ...  125    4 3077]\n"," [4468  189    4 ...    9   57  975]\n"," ...\n"," [   0    0    0 ...   21  846 5518]\n"," [   0    0    0 ... 2302    7  470]\n"," [   0    0    0 ...   34 2005 2643]]\n"]}],"source":["def load_data():\n","    #load dataset from keras\n","    (X_train, Y_train), (X_test, Y_test) = datasets.imdb.load_data(num_words=n_words)\n","    #pad data\n","    X_train = preprocessing.sequence.pad_sequences(X_train, maxlen=max_len)\n","    X_test = preprocessing.sequence.pad_sequences(X_test, maxlen=max_len)\n","    return (X_train, Y_train), (X_test, Y_test)\n","\n","(X_train, Y_train), (X_test, Y_test) = load_data()\n","print(X_test)"]},{"cell_type":"markdown","metadata":{"cell_id":"a1756330b0a34906a55287ac9aeb31ed","deepnote_cell_type":"text-cell-h2","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["## Build the model"]},{"cell_type":"markdown","metadata":{"cell_id":"4dfa001a6fb1411cac005d4bb5b06c1a","deepnote_cell_type":"text-cell-bullet","formattedRanges":[{"fromCodePoint":10,"marks":{"code":true},"toCodePoint":20,"type":"marks"}],"is_collapsed":false,"tags":[]},"source":["- We use an embedding layer as input, this maps words to a more dense feature space"]},{"cell_type":"markdown","metadata":{"cell_id":"19ce2f94-c9f9-46ef-9239-f036da212a7a","deepnote_cell_type":"text-cell-bullet","formattedRanges":[{"fromCodePoint":14,"marks":{"code":true},"toCodePoint":25,"type":"marks"}],"is_collapsed":false,"tags":[]},"source":["- We then use a maxpooling layer, that takes the may value from of either feature vector across the n_words"]},{"cell_type":"markdown","metadata":{"cell_id":"5c5f6f0f-4df5-4608-9e33-3196f991a177","deepnote_cell_type":"text-cell-bullet","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["- We then have two dense layers."]},{"cell_type":"markdown","metadata":{"cell_id":"eb18779e-92a7-4006-89cb-2007b0b616ce","deepnote_cell_type":"text-cell-bullet","formattedRanges":[{"fromCodePoint":41,"marks":{"code":true},"toCodePoint":48,"type":"marks"},{"fromCodePoint":139,"ranges":[],"toCodePoint":139,"type":"link","url":"https://deepai.org/machine-learning-glossary-and-terms/softmax-layer"}],"is_collapsed":false,"tags":[]},"source":["- The last layer is a single neuron with a sigmoid activation function, which we will interpret as a probability that the review is favorable"]},{"cell_type":"code","execution_count":4,"metadata":{"cell_id":"0ff8afdd30514941b2acc1a1ec2f8988","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":196,"execution_start":1667664699908,"source_hash":"1d3643cc","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 200, 256)          2560000   \n","                                                                 \n"," dropout (Dropout)           (None, 200, 256)          0         \n","                                                                 \n"," global_max_pooling1d (Globa  (None, 256)              0         \n"," lMaxPooling1D)                                                  \n","                                                                 \n"," dense (Dense)               (None, 128)               32896     \n","                                                                 \n"," dropout_1 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 2,593,025\n","Trainable params: 2,593,025\n","Non-trainable params: 0\n","_________________________________________________________________\n","2022-11-05 16:11:39.907030: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n","2022-11-05 16:11:39.907062: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n","2022-11-05 16:11:39.907079: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (p-ba4822a4-198a-4cdb-8280-0ca8d044b999): /proc/driver/nvidia/version does not exist\n","2022-11-05 16:11:39.907299: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["def build_model():\n","    model = models.Sequential()\n","\n","    model.add(\n","        layers.Embedding(\n","        n_words,\n","        dim_embedding,\n","        input_length=max_len\n","        )\n","    )\n","    model.add(\n","        layers.Dropout(DROPOUT)\n","    )\n","    model.add(\n","        layers.GlobalMaxPooling1D()\n","    )\n","    model.add(\n","        layers.Dense(\n","            128,\n","            activation = ACTIVATION_FUNCTION_HIDDEN\n","        ) \n","    )\n","    model.add(\n","        layers.Dropout(DROPOUT+0.2)\n","    )    \n","    model.add(\n","        layers.Dense(\n","            1,\n","            activation = ACTIVATION_FUNCTION_FINAL\n","        ) \n","    )\n","\n","    return model\n","    \n","model = build_model()\n","model.summary()"]},{"cell_type":"markdown","metadata":{"cell_id":"fcc959b6d6ee4987b3c2076f6e6f5838","deepnote_cell_type":"text-cell-h2","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["## Compile the model"]},{"cell_type":"markdown","metadata":{"cell_id":"3f79f0770c3044d88565ece8e7b1dca5","deepnote_cell_type":"text-cell-bullet","formattedRanges":[{"fromCodePoint":7,"marks":{"code":true},"toCodePoint":12,"type":"marks"}],"is_collapsed":false,"tags":[]},"source":["- We use adam as optimizer"]},{"cell_type":"markdown","metadata":{"cell_id":"e0d88fa0f5ff4344ae1778d6e0c8a5c7","deepnote_cell_type":"text-cell-bullet","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["- The loss function is categorical cross-entropy, this is particularly well-suited for multi-class problems with a one-hot encoding "]},{"cell_type":"markdown","metadata":{"cell_id":"d30cb009030d417385574dffecc3bf77","deepnote_cell_type":"text-cell-bullet","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["- We use accuracy to evaluate the performance of the model"]},{"cell_type":"code","execution_count":5,"metadata":{"cell_id":"f51c903fa2824ec0a794b040dab715d4","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":0,"execution_start":1667664700103,"source_hash":"c27cdea0","tags":[]},"outputs":[],"source":["model.compile(\n","    optimizer=OPTIMIZER,\n","    loss=LOSS_FUNCTION,\n","    metrics=METRICS\n",")"]},{"cell_type":"markdown","metadata":{"cell_id":"8e6796b30a4e42c19ae3032e9200c0de","deepnote_cell_type":"text-cell-h2","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["## Train the model"]},{"cell_type":"markdown","metadata":{"cell_id":"bb29293690384a3ca5935360d4b49c4c","deepnote_cell_type":"text-cell-p","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["We are now ready to train the model. We need to define the number of epochs and the batch size. "]},{"cell_type":"markdown","metadata":{"cell_id":"0a0d17b17cfb41ffac857a46b06e9502","deepnote_cell_type":"text-cell-bullet","formattedRanges":[{"fromCodePoint":0,"marks":{"code":true},"toCodePoint":7,"type":"marks"}],"is_collapsed":false,"tags":[]},"source":["- Epochs are the number of times the model is exposed to the training dataset. Each time, it will run the optimizer (SGD) and try to minimize the loss function. "]},{"cell_type":"markdown","metadata":{"cell_id":"befe85df6fbd4eeca24fac6a602a3294","deepnote_cell_type":"text-cell-bullet","formattedRanges":[{"fromCodePoint":0,"marks":{"code":true},"toCodePoint":10,"type":"marks"}],"is_collapsed":false,"tags":[]},"source":["- Batch_size is the number of instances that the optimizer observes before tuning the weights and biases. There are many batches per epoch."]},{"cell_type":"markdown","metadata":{"cell_id":"b9ad143b41fe41b2a17505a3c19fe047","deepnote_cell_type":"text-cell-bullet","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["- We split the training data in an 80% training and 20% validation per epoch. The validation set is used to compute the metric and tune hyperparameters, to avoid overfitting."]},{"cell_type":"markdown","metadata":{"cell_id":"f4cc24f36f2146169952a1474abdecae","deepnote_cell_type":"text-cell-bullet","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["- We add early stopping, on the loss function on the validation set, with a patience of N epoch. This will stop the optimization if the loss function does not go down for N  consecutive epochs. "]},{"cell_type":"code","execution_count":6,"metadata":{"cell_id":"800c6751589d4667a02f3fce4c5df9c0","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":670894,"execution_start":1667664700104,"source_hash":"951e092d","tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n","Epoch 1/20\n","50/50 [==============================] - ETA: 0s - loss: 0.6751 - accuracy: 0.5890INFO:tensorflow:Assets written to: /work/wandb/run-20221105_161135-3r1q2yz1/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_161135-3r1q2yz1/files/model-best)... Done. 0.1s\n","50/50 [==============================] - 34s 671ms/step - loss: 0.6751 - accuracy: 0.5890 - val_loss: 0.6386 - val_accuracy: 0.7696\n","Epoch 2/20\n","50/50 [==============================] - ETA: 0s - loss: 0.4822 - accuracy: 0.8292INFO:tensorflow:Assets written to: /work/wandb/run-20221105_161135-3r1q2yz1/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_161135-3r1q2yz1/files/model-best)... Done. 0.1s\n","50/50 [==============================] - 33s 666ms/step - loss: 0.4822 - accuracy: 0.8292 - val_loss: 0.3779 - val_accuracy: 0.8542\n","Epoch 3/20\n","50/50 [==============================] - ETA: 0s - loss: 0.2880 - accuracy: 0.8801INFO:tensorflow:Assets written to: /work/wandb/run-20221105_161135-3r1q2yz1/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_161135-3r1q2yz1/files/model-best)... Done. 0.1s\n","50/50 [==============================] - 33s 661ms/step - loss: 0.2880 - accuracy: 0.8801 - val_loss: 0.3066 - val_accuracy: 0.8736\n","Epoch 4/20\n","50/50 [==============================] - ETA: 0s - loss: 0.2202 - accuracy: 0.9138INFO:tensorflow:Assets written to: /work/wandb/run-20221105_161135-3r1q2yz1/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_161135-3r1q2yz1/files/model-best)... Done. 0.2s\n","50/50 [==============================] - 33s 659ms/step - loss: 0.2202 - accuracy: 0.9138 - val_loss: 0.2944 - val_accuracy: 0.8755\n","Epoch 5/20\n","50/50 [==============================] - 32s 644ms/step - loss: 0.1741 - accuracy: 0.9364 - val_loss: 0.2946 - val_accuracy: 0.8737\n","Epoch 6/20\n","50/50 [==============================] - ETA: 0s - loss: 0.1349 - accuracy: 0.9543INFO:tensorflow:Assets written to: /work/wandb/run-20221105_161135-3r1q2yz1/files/model-best/assets\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/work/wandb/run-20221105_161135-3r1q2yz1/files/model-best)... Done. 0.1s\n","50/50 [==============================] - 33s 661ms/step - loss: 0.1349 - accuracy: 0.9543 - val_loss: 0.2924 - val_accuracy: 0.8754\n","Epoch 7/20\n","50/50 [==============================] - 32s 647ms/step - loss: 0.1025 - accuracy: 0.9678 - val_loss: 0.3063 - val_accuracy: 0.8692\n","Epoch 8/20\n","50/50 [==============================] - 32s 643ms/step - loss: 0.0776 - accuracy: 0.9773 - val_loss: 0.3224 - val_accuracy: 0.8645\n","Epoch 9/20\n","50/50 [==============================] - 32s 647ms/step - loss: 0.0583 - accuracy: 0.9839 - val_loss: 0.3379 - val_accuracy: 0.8629\n","Epoch 10/20\n","50/50 [==============================] - 36s 717ms/step - loss: 0.0433 - accuracy: 0.9890 - val_loss: 0.3562 - val_accuracy: 0.8596\n","Epoch 11/20\n","50/50 [==============================] - 32s 642ms/step - loss: 0.0321 - accuracy: 0.9930 - val_loss: 0.3727 - val_accuracy: 0.8578\n","Epoch 12/20\n","50/50 [==============================] - 32s 643ms/step - loss: 0.0250 - accuracy: 0.9947 - val_loss: 0.3898 - val_accuracy: 0.8558\n","Epoch 13/20\n","50/50 [==============================] - 32s 647ms/step - loss: 0.0187 - accuracy: 0.9963 - val_loss: 0.4103 - val_accuracy: 0.8535\n","Epoch 14/20\n","50/50 [==============================] - 36s 732ms/step - loss: 0.0154 - accuracy: 0.9971 - val_loss: 0.4261 - val_accuracy: 0.8524\n","Epoch 15/20\n","50/50 [==============================] - 36s 721ms/step - loss: 0.0127 - accuracy: 0.9974 - val_loss: 0.4418 - val_accuracy: 0.8492\n","Epoch 16/20\n","50/50 [==============================] - 42s 840ms/step - loss: 0.0102 - accuracy: 0.9988 - val_loss: 0.4495 - val_accuracy: 0.8513\n","Epoch 17/20\n","50/50 [==============================] - 32s 649ms/step - loss: 0.0088 - accuracy: 0.9988 - val_loss: 0.4672 - val_accuracy: 0.8495\n","Epoch 18/20\n","50/50 [==============================] - 32s 651ms/step - loss: 0.0077 - accuracy: 0.9988 - val_loss: 0.4730 - val_accuracy: 0.8520\n","Epoch 19/20\n","50/50 [==============================] - 32s 639ms/step - loss: 0.0064 - accuracy: 0.9990 - val_loss: 0.4898 - val_accuracy: 0.8505\n","Epoch 20/20\n","50/50 [==============================] - 32s 643ms/step - loss: 0.0052 - accuracy: 0.9994 - val_loss: 0.5046 - val_accuracy: 0.8498\n"]}],"source":["score = model.fit(\n","    X_train,\n","    Y_train,\n","    batch_size=BATCH_SIZE,\n","    epochs=EPOCHS,\n","    verbose=VERBOSE,\n","    validation_data=(X_test, Y_test),\n","    callbacks=[WandbCallback()]\n","    )"]},{"cell_type":"markdown","metadata":{"cell_id":"d913a535595f4333be10de48c97348e3","deepnote_cell_type":"text-cell-h2","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["## Test the model on unseen data"]},{"cell_type":"code","execution_count":7,"metadata":{"cell_id":"8651c6ccef9c406e8c8cff273bd848a5","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":2358,"execution_start":1667665371004,"source_hash":"1d89c494","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["50/50 [==============================] - 2s 41ms/step - loss: 0.5046 - accuracy: 0.8498\n"]}],"source":["test_loss, test_accuracy = model.evaluate(X_test, Y_test, batch_size=BATCH_SIZE)\n","#track test results on wandb\n","wandb.log({\n","    \"test_loss\": test_loss, \n","    \"test_accuracy\": test_accuracy\n","})"]},{"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown","tags":[]},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=ba4822a4-198a-4cdb-8280-0ca8d044b999' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_full_width":true,"deepnote_notebook_id":"0c3efa607dff4878a1e27f38a68d86c0","language_info":{"name":"python"},"orig_nbformat":2},"nbformat":4,"nbformat_minor":0}
