{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"ddbae6260b064f8ea820c78cefc164f3","deepnote_cell_type":"text-cell-h1","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["# VGG16 model from Keras and transfer learning"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"51e6196e45254c049f91a694d3126252","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":90013,"execution_start":1670441462741,"source_hash":"e0d8250f","tags":[]},"outputs":[],"source":["!apt-get update && apt-get install -y python3-opencv\n","!pip install opencv-python\n","!pip install matplotlib\n","!pip install wandb\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"522db337a5634a38aeb2255d04513a64","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":151814,"execution_start":1669575520648,"source_hash":"47c33029","tags":[]},"outputs":[],"source":["import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import cv2\n","\n","import wandb\n","from wandb.keras import WandbCallback\n","\n","wandb.init(project='vgg16-transfer-learning', entity='picklerick')\n","\n","#---------------HYPERPARAMETERS--------------------\n","WEIGHTS = 'imagenet'\n","INLCUDE_TOP = True\n","OPTIMIZER = 'sgd'\n","LOSS_FUNCTION = 'categorical_crossentropy'\n","\n","wandb.config = {\n","  'include_top': INLCUDE_TOP, \n","  'weights': WEIGHTS,\n","  'optimizer': OPTIMIZER,\n","  'loss_function': LOSS_FUNCTION,\n","}"]},{"cell_type":"markdown","metadata":{"cell_id":"9acb1083b045478281099bd69f75f824","deepnote_cell_type":"text-cell-h2","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["## Load base model "]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"e3d19073bfbd48239ac9f981877cd47c","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":4890,"execution_start":1670441406419,"source_hash":"dc08b798","tags":[]},"outputs":[],"source":["base_model = tf.keras.applications.VGG16(weights=WEIGHTS, include_top=INLCUDE_TOP)\n","print(base_model)\n","for index, layer in enumrate(base_model.layers)\n","    print(index, layer.name, layer.output_shape)"]},{"cell_type":"markdown","metadata":{"cell_id":"71d12da2b06146818bc55c0cc8d9b920","deepnote_cell_type":"text-cell-h2","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["## Load image and resize to input of VGG16"]},{"cell_type":"code","execution_count":6,"metadata":{"cell_id":"78e544a79c1f461c98f573bbb7622a3f","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":11,"execution_start":1669575706021,"source_hash":"949a4080","tags":[]},"outputs":[],"source":["image = cv2.resize(cv2.imread('locomotive.jpg'), (224,224))\n","im = np.expand_dims(image,axis=0)"]},{"cell_type":"markdown","metadata":{"cell_id":"d96f153b63ea49bb8c1c6a30f76b2ff7","deepnote_cell_type":"text-cell-h2","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["## Predict class of input image"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"5fc8ad02e09140d3be4e2e637ae03241","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":1059,"execution_start":1669575710502,"source_hash":"ad6c5ef9","tags":[]},"outputs":[],"source":["out = model.predict(im)\n","index = np.argmax(out)\n","print('Output of the network: ',out)\n","print('Top class prediction: ',index)\n","\n","plt.plot(out.ravel())\n","plt.show()"]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"19b30b89e79f493584ee57f6806409cd","language_info":{"name":"python"},"orig_nbformat":2},"nbformat":4,"nbformat_minor":0}
